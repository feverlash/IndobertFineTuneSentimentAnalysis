{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"bert_sentiment_analysis_tensorflow.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"include_colab_link":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bd1eaca97cfa42e3a84bc163b0cd8b36":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9aa839235bec4405a9fd890f4085f838","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ecc84673e4e94c7792738d1b0492edeb","IPY_MODEL_8657e7c91e3149ab8e806ea7290c3f90"]}},"9aa839235bec4405a9fd890f4085f838":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ecc84673e4e94c7792738d1b0492edeb":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_322f337669af4fbbae9382985603b21c","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":810912,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":810912,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4250487d8aa24d49ad05c38209a9eaff"}},"8657e7c91e3149ab8e806ea7290c3f90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_622a0ca5191247049b5f430b41a705f5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 811k/811k [00:00&lt;00:00, 880kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53faa0f0a22949a4ae796a49cb867644"}},"322f337669af4fbbae9382985603b21c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4250487d8aa24d49ad05c38209a9eaff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"622a0ca5191247049b5f430b41a705f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"53faa0f0a22949a4ae796a49cb867644":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2659f149ad904b75adfbb235d160eb43":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a38913dbbadf42da9143840fca7a3e4e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_887a40e4e13f45db8ebd2f9cb2fe1556","IPY_MODEL_9da2f0970af2442ea8aa9aceabe3749f"]}},"a38913dbbadf42da9143840fca7a3e4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"887a40e4e13f45db8ebd2f9cb2fe1556":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fd801380487942618aff7722688f0378","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":596,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":596,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33df35db99964b05a3c4d222e69b920e"}},"9da2f0970af2442ea8aa9aceabe3749f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3c0b0493c4714e279496e307c76d8a9e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 596/596 [00:00&lt;00:00, 15.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_11c9e525eb644cc28d59ab6008563f06"}},"fd801380487942618aff7722688f0378":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"33df35db99964b05a3c4d222e69b920e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c0b0493c4714e279496e307c76d8a9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"11c9e525eb644cc28d59ab6008563f06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"acd963b011514156ba238f1d7236a9e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fe3ce0fe59e346959af5d5a71232e96e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1e0e75b1097c460dbb15b12ee2ca4685","IPY_MODEL_13e31a2bc4454ef5b9e0235ef7085cb4"]}},"fe3ce0fe59e346959af5d5a71232e96e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e0e75b1097c460dbb15b12ee2ca4685":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ad5cef2c767e46feb198448d79aaeb87","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":545172724,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":545172724,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e2de9226c37044348a6973e2a55931fa"}},"13e31a2bc4454ef5b9e0235ef7085cb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_71b3867e57a541a7869f79adfcac97a4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 545M/545M [00:48&lt;00:00, 11.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_32293fb2e5fe4519a71527e07b018f53"}},"ad5cef2c767e46feb198448d79aaeb87":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e2de9226c37044348a6973e2a55931fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71b3867e57a541a7869f79adfcac97a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"32293fb2e5fe4519a71527e07b018f53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e827172829e429eaf7ea66ede3a18be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b44e4263bd5f4efe86343f450feaea6c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_92e2b3f8b23b47b0b7441411a56c0e01","IPY_MODEL_d083403b2a914b458369fdb8e29c0ab2"]}},"b44e4263bd5f4efe86343f450feaea6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"92e2b3f8b23b47b0b7441411a56c0e01":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_291481541cba4328975825528f8e216c","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":152672,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":152672,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e02ff2aac71848f0b152ee7415314efd"}},"d083403b2a914b458369fdb8e29c0ab2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_99429733f14e40f68b1297fe8a9f5dc6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 152672/152672 [00:18&lt;00:00, 8070.37it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_acc2594d8a3e4df99db50b6299cb5ee1"}},"291481541cba4328975825528f8e216c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e02ff2aac71848f0b152ee7415314efd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"99429733f14e40f68b1297fe8a9f5dc6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"acc2594d8a3e4df99db50b6299cb5ee1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10554710,"sourceType":"datasetVersion","datasetId":6530234}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bert Sentiment Analysis - TensorFlow","metadata":{"id":"bodW3MxmAnLO"}},{"cell_type":"markdown","source":"## Import","metadata":{"id":"8GULw0OlAnLS"}},{"cell_type":"code","source":"!pip install tensorflow-gpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:02:49.894660Z","iopub.execute_input":"2025-01-25T14:02:49.894998Z","iopub.status.idle":"2025-01-25T14:02:51.636942Z","shell.execute_reply.started":"2025-01-25T14:02:49.894968Z","shell.execute_reply":"2025-01-25T14:02:51.635859Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorflow-gpu\n  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m See above for output.\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install missing librairies\n!pip install transformers","metadata":{"id":"ZVIKqoy7EMmS","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:02:51.638069Z","iopub.execute_input":"2025-01-25T14:02:51.638418Z","iopub.status.idle":"2025-01-25T14:02:55.525985Z","shell.execute_reply.started":"2025-01-25T14:02:51.638385Z","shell.execute_reply":"2025-01-25T14:02:55.524972Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom datasets import load_dataset, concatenate_datasets\nfrom datetime import datetime\nfrom tqdm import tqdm_notebook\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom datasets import load_dataset, concatenate_datasets\nfrom transformers import TFBertModel, AutoTokenizer\nfrom transformers import DataCollatorWithPadding\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import  Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\nfrom tqdm import tqdm\n\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom transformers import BertTokenizer, BertForSequenceClassification, TFBertForSequenceClassification","metadata":{"id":"2hX6oilKAnLU","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:02:55.527086Z","iopub.execute_input":"2025-01-25T14:02:55.527425Z","iopub.status.idle":"2025-01-25T14:03:17.373682Z","shell.execute_reply.started":"2025-01-25T14:02:55.527394Z","shell.execute_reply":"2025-01-25T14:03:17.372771Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (16, 9)","metadata":{"id":"xSgbRcT5AnLZ","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:17.375223Z","iopub.execute_input":"2025-01-25T14:03:17.375840Z","iopub.status.idle":"2025-01-25T14:03:17.379600Z","shell.execute_reply.started":"2025-01-25T14:03:17.375817Z","shell.execute_reply":"2025-01-25T14:03:17.378713Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 2. Load the STSB dataset: https://huggingface.co/datasets/sentence-transformers/stsb\ntrain_dataset = load_dataset(\"/kaggle/input/smsa-dataset\", split=\"train\")\neval_dataset = load_dataset(\"/kaggle/input/smsa-dataset\", split=\"validation\")\ntest_dataset = load_dataset(\"/kaggle/input/smsa-dataset\", split=\"test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:17.381369Z","iopub.execute_input":"2025-01-25T14:03:17.381608Z","iopub.status.idle":"2025-01-25T14:03:17.827436Z","shell.execute_reply.started":"2025-01-25T14:03:17.381588Z","shell.execute_reply":"2025-01-25T14:03:17.826629Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"673427fe4ec34a5f8b4a958cc9407694"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55b004826f33451790efe7e0942e8464"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2631140211f5400f9a76954ab5f0830e"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('indobenchmark/indobert-base-p1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:17.828182Z","iopub.execute_input":"2025-01-25T14:03:17.828446Z","iopub.status.idle":"2025-01-25T14:03:19.427545Z","shell.execute_reply.started":"2025-01-25T14:03:17.828425Z","shell.execute_reply":"2025-01-25T14:03:19.426837Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc9b8106c81446e1a27b94da4ee93c2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f04c8aad2f54302afba34cae549456f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c852881c0d434cbc927b54e7e2edbed3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9cadd48529e49c18b6eb644e069bda6"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"max_length = 128\nbatch_size = 32\neval_batch_size = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:19.428280Z","iopub.execute_input":"2025-01-25T14:03:19.428521Z","iopub.status.idle":"2025-01-25T14:03:19.432129Z","shell.execute_reply.started":"2025-01-25T14:03:19.428501Z","shell.execute_reply":"2025-01-25T14:03:19.431441Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def map_sentiment_to_int(example):\n    sentiment_mapping = {\n        \"positive\": 1,\n        \"negative\": 0,\n        \"neutral\": 2  # Tambahkan label lain jika perlu\n    }\n    # Ganti nilai sentiment dengan integer\n    example[\"sentiment\"] = sentiment_mapping[example[\"sentiment\"]]\n    return example\n\ntrain_dataset = train_dataset.map(map_sentiment_to_int)\neval_dataset = eval_dataset.map(map_sentiment_to_int)\ntest_dataset = test_dataset.map(map_sentiment_to_int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:19.432879Z","iopub.execute_input":"2025-01-25T14:03:19.433072Z","iopub.status.idle":"2025-01-25T14:03:19.989332Z","shell.execute_reply.started":"2025-01-25T14:03:19.433055Z","shell.execute_reply":"2025-01-25T14:03:19.988439Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e336673a8af3479ab2697cc40e31ca3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1259 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18a859ae558445329e7d9ac980b50a39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/499 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97049d1c561a4d7cbb0366b3a19bcfdb"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def tokenize_function(examples):\n    # Tokenize sentences and return tensors\n    return tokenizer(\n        examples[\"text\"],  # Kolom teks\n        padding=\"max_length\",  # Pastikan semua input memiliki panjang sama\n        truncation=True,\n        max_length=max_length,\n        return_tensors=\"np\",  # Pastikan format numpy\n    )\n\ntrain_ds = train_dataset.map(tokenize_function, batched=True)\neval_ds = eval_dataset.map(tokenize_function, batched=True)\ntest_ds = test_dataset.map(tokenize_function, batched=True)\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# 4. Prepare dataset for TensorFlow\ntrain_dataset = train_ds.to_tf_dataset(\n    columns=['input_ids', 'attention_mask'],\n    label_cols=['sentiment'],\n    shuffle=True,\n    batch_size=batch_size,\n    collate_fn=data_collator,\n)\neval_dataset = eval_ds.to_tf_dataset(\n    columns=['input_ids', 'attention_mask'],\n    label_cols=['sentiment'],\n    shuffle=False,\n    batch_size=eval_batch_size,\n    collate_fn=data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:19.990303Z","iopub.execute_input":"2025-01-25T14:03:19.990573Z","iopub.status.idle":"2025-01-25T14:03:22.353952Z","shell.execute_reply.started":"2025-01-25T14:03:19.990551Z","shell.execute_reply":"2025-01-25T14:03:22.353067Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10932 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d25df0309e34d20945bc2d2a5f180b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1259 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46511efff287439ebd5db4577cc203cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/499 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c42200dba554d0ab55b6cd9aee375d7"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py:403: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\nOld behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \nNew behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n  warnings.warn(\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### Read dataset","metadata":{"id":"7ZUDHyhwD3yg"}},{"cell_type":"code","source":"# import pandas as pd\n\n# # Load your dataset\n# data_path = \"/kaggle/input/smsa-dataset/train_preprocess.csv\"  # Replace with your file path\n# df = pd.read_csv(data_path)\n\n# # Print column names\n# print(df.columns)\n\n# # Rename columns for clarity\n# df.columns = ['text', 'sentiment']  # Rename the columns appropriately","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:22.354823Z","iopub.execute_input":"2025-01-25T14:03:22.355077Z","iopub.status.idle":"2025-01-25T14:03:22.358319Z","shell.execute_reply.started":"2025-01-25T14:03:22.355049Z","shell.execute_reply":"2025-01-25T14:03:22.357492Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# # Remove duplicate rows\n# df = df.drop_duplicates()\n\n# # Remove duplicate column names if any\n# df = df.loc[:, ~df.columns.duplicated()]\n\n\n# # Drop rows with missing values in any column\n# df = df.dropna()\n\n# # Check for empty strings or invalid entries\n# df = df[df['text'].str.strip() != '']  # Remove rows with empty 'text' field\n# df = df[df['sentiment'].str.strip() != '']  # Remove rows with empty 'sentiment' field\n\n# # Ensure sentiment labels are consistent\n# valid_sentiments = {'positive', 'negative', 'neutral'}\n# df = df[df['sentiment'].isin(valid_sentiments)]  # Keep only valid labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:22.359683Z","iopub.execute_input":"2025-01-25T14:03:22.359926Z","iopub.status.idle":"2025-01-25T14:03:22.398964Z","shell.execute_reply.started":"2025-01-25T14:03:22.359899Z","shell.execute_reply":"2025-01-25T14:03:22.398118Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:22.399856Z","iopub.execute_input":"2025-01-25T14:03:22.400225Z","iopub.status.idle":"2025-01-25T14:03:22.414499Z","shell.execute_reply.started":"2025-01-25T14:03:22.400197Z","shell.execute_reply":"2025-01-25T14:03:22.413592Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# df.to_csv(\"cleaned_dataset.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:22.417892Z","iopub.execute_input":"2025-01-25T14:03:22.418165Z","iopub.status.idle":"2025-01-25T14:03:22.427723Z","shell.execute_reply.started":"2025-01-25T14:03:22.418146Z","shell.execute_reply":"2025-01-25T14:03:22.426975Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"model = TFBertForSequenceClassification.from_pretrained('indobenchmark/indobert-base-p1', num_labels=3)","metadata":{"id":"bpDgEuCEAnMK","outputId":"4f70987c-873e-489c-835c-d74d4aa33073","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:22.428944Z","iopub.execute_input":"2025-01-25T14:03:22.429223Z","iopub.status.idle":"2025-01-25T14:03:27.208577Z","shell.execute_reply.started":"2025-01-25T14:03:22.429190Z","shell.execute_reply":"2025-01-25T14:03:27.207743Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tf_model.h5:   0%|          | 0.00/656M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"392d0a18e89242e686c0763336423644"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n\nSome layers of TFBertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model","metadata":{"id":"LbpVOXLrAnMP","outputId":"05f207f5-f420-4078-a71a-aee7bbc42f36","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:27.209616Z","iopub.execute_input":"2025-01-25T14:03:27.209991Z","iopub.status.idle":"2025-01-25T14:03:27.214950Z","shell.execute_reply.started":"2025-01-25T14:03:27.209947Z","shell.execute_reply":"2025-01-25T14:03:27.213870Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification at 0x7a42a09c7670>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# Hyperparameters\nepochs = 5\nlearning_rate = 5e-5\n\n# Compile the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmetrics_fn = tf.keras.metrics.SparseCategoricalAccuracy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:27.215882Z","iopub.execute_input":"2025-01-25T14:03:27.216165Z","iopub.status.idle":"2025-01-25T14:03:27.267168Z","shell.execute_reply.started":"2025-01-25T14:03:27.216138Z","shell.execute_reply":"2025-01-25T14:03:27.266407Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:27.268173Z","iopub.execute_input":"2025-01-25T14:03:27.268483Z","iopub.status.idle":"2025-01-25T14:03:27.469295Z","shell.execute_reply.started":"2025-01-25T14:03:27.268456Z","shell.execute_reply":"2025-01-25T14:03:27.468253Z"}},"outputs":[{"name":"stdout","text":"Sat Jan 25 14:03:27 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   35C    P0             31W /  250W |    1285MiB /  16384MiB |      7%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import tensorflow as tf\nimport time\nimport random\nfrom tqdm import tqdm\nfrom transformers import create_optimizer, AdamW\nfrom datetime import timedelta\n\ndef format_time(elapsed):\n    return str(timedelta(seconds=int(round((elapsed)))))\n\ndef train():\n    seed_val = 42\n\n    random.seed(seed_val)\n    np.random.seed(seed_val)\n    tf.random.set_seed(seed_val)\n\n    # Prepare optimizer, learning rate scheduler\n    steps_per_epoch = len(train_dataset) // batch_size\n    num_train_steps = steps_per_epoch * epochs\n\n    # Metrics to track loss\n    train_loss = tf.keras.metrics.Mean(name='train_loss')\n    val_loss = tf.keras.metrics.Mean(name='val_loss')\n    train_accuracy = tf.keras.metrics.Mean(name=\"train_accuracy\")\n    val_accuracy = tf.keras.metrics.Mean(name=\"val_accuracy\")\n\n    # Training and validation loops\n    training_stats = []\n    total_t0 = time.time()\n\n    for epoch_i in range(epochs):\n        print(f\"======== Epoch {epoch_i + 1} / {epochs} ========\")\n        print('Training...')\n\n        t0 = time.time()\n\n        total_train_loss = 0\n\n        for batch in tqdm(train_dataset):\n            with tf.GradientTape() as tape:\n                input, labels = batch\n                input_ids = input['input_ids']\n                attention_mask = input['attention_mask']\n\n                embeddings = model((input_ids, attention_mask), training=True)\n                \n                logits = embeddings.logits\n        \n                # Calculate loss using the logits\n                loss = loss_fn(labels, logits)\n                metrics = metrics_fn(labels, logits)\n\n            train_loss(loss)\n            train_accuracy(metrics)\n            \n            gradients = tape.gradient(loss, model.trainable_variables)\n            optimizer.apply_gradients(zip(gradients, model.trainable_variables))            \n\n        avg_train_loss = train_loss.result()\n        avg_train_accuracy = train_accuracy.result()\n        training_time = format_time(time.time() - t0)\n\n        print(f\"  Average training loss: {avg_train_loss:.5f}\")\n        print(f\"  Average training accuracy: {avg_train_accuracy:.5f}\")\n        print(f\"  Training epoch took: {training_time}\")\n\n        # ========================================\n        #               Validation\n        # ========================================\n        print(\"Running Validation...\")\n\n        t0 = time.time()\n\n        total_val_loss = 0\n\n\n        for batch in tqdm(eval_dataset):\n            input, labels = batch\n            input_ids = input['input_ids']\n            attention_mask = input['attention_mask']\n\n            embeddings = model((input_ids, attention_mask), training=True)\n                \n            logits = embeddings.logits\n    \n            # Calculate loss using the logits\n            loss = loss_fn(labels, logits)\n            metrics = metrics_fn(labels, logits)\n\n            val_loss(loss)\n            val_accuracy(metrics)\n\n        avg_val_loss = val_loss.result()\n        avg_val_accuracy = val_accuracy.result()\n        validation_time = format_time(time.time() - t0)\n\n        print(f\"  Validation Loss: {avg_val_loss:.5f}\")\n        print(f\"  Validation Accuracy: {avg_val_accuracy:.5f}\")\n        print(f\"  Validation took: {validation_time}\")\n\n        # Record all statistics from this epoch.\n        training_stats.append(\n            {\n                'epoch': epoch_i + 1,\n                'Training Loss': avg_train_loss.numpy(),\n                'Valid. Loss': avg_val_loss.numpy(),\n                'Training Time': training_time,\n                'Validation Time': validation_time\n            }\n        )\n\n    print(\"Training complete!\")\n    print(f\"Total training took {format_time(time.time() - total_t0)} (h:mm:ss)\")\n\n    return model, training_stats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:27.470632Z","iopub.execute_input":"2025-01-25T14:03:27.470988Z","iopub.status.idle":"2025-01-25T14:03:27.489996Z","shell.execute_reply.started":"2025-01-25T14:03:27.470943Z","shell.execute_reply":"2025-01-25T14:03:27.489093Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"model, training_stats = train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:03:27.490949Z","iopub.execute_input":"2025-01-25T14:03:27.491221Z","iopub.status.idle":"2025-01-25T14:43:28.339401Z","shell.execute_reply.started":"2025-01-25T14:03:27.491195Z","shell.execute_reply":"2025-01-25T14:43:28.338677Z"}},"outputs":[{"name":"stdout","text":"======== Epoch 1 / 5 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 342/342 [07:54<00:00,  1.39s/it]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.24711\n  Average training accuracy: 0.88149\n  Training epoch took: 0:07:55\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:09<00:00,  4.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.21070\n  Validation Accuracy: 0.91305\n  Validation took: 0:00:10\n======== Epoch 2 / 5 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 342/342 [07:49<00:00,  1.37s/it]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.18438\n  Average training accuracy: 0.90413\n  Training epoch took: 0:07:50\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:09<00:00,  4.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.21067\n  Validation Accuracy: 0.92387\n  Validation took: 0:00:10\n======== Epoch 3 / 5 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 342/342 [07:51<00:00,  1.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.15018\n  Average training accuracy: 0.91661\n  Training epoch took: 0:07:51\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:09<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.21351\n  Validation Accuracy: 0.93139\n  Validation took: 0:00:09\n======== Epoch 4 / 5 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 342/342 [07:49<00:00,  1.37s/it]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.12846\n  Average training accuracy: 0.92503\n  Training epoch took: 0:07:50\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:09<00:00,  4.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.21917\n  Validation Accuracy: 0.93690\n  Validation took: 0:00:10\n======== Epoch 5 / 5 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 342/342 [07:47<00:00,  1.37s/it]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.11011\n  Average training accuracy: 0.93134\n  Training epoch took: 0:07:48\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 40/40 [00:09<00:00,  4.22it/s]","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.23667\n  Validation Accuracy: 0.94136\n  Validation took: 0:00:09\nTraining complete!\nTotal training took 0:40:01 (h:mm:ss)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Test model on new sentences","metadata":{"id":"bLrxGjqvAnNH"}},{"cell_type":"code","source":"def predict(text):\n    # pre-process text\n    encoded_text = tokenizer.encode(text)\n\n    input_ = tf.expand_dims(encoded_text, 0)\n\n    logits = model(input_)[0][0]\n    pred = tf.nn.softmax(logits).numpy()\n    \n    return pred","metadata":{"id":"VQKIrG8gAnNJ","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:44:30.737189Z","iopub.execute_input":"2025-01-25T14:44:30.737644Z","iopub.status.idle":"2025-01-25T14:44:30.742928Z","shell.execute_reply.started":"2025-01-25T14:44:30.737604Z","shell.execute_reply":"2025-01-25T14:44:30.742069Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def predict(text):\n    \n    sentiment_mapping = {\n    \"positive\": 1,\n    \"negative\": 0,\n    \"neutral\": 2\n    }\n    \n    inputs = tokenizer(\n        text,\n        return_tensors=\"tf\",\n        truncation=True,\n        padding=\"max_length\", \n        max_length=128         \n    )\n    \n    #prediksi menggunakan model\n    outputs = model(inputs)\n    \n    logits = outputs.logits\n    \n    #probabilitas \n    probabilities = tf.nn.softmax(logits).numpy()\n    \n    #indeks label prediksi\n    predicted_index = int(tf.argmax(probabilities, axis=1).numpy()[0])  # Konversi ke integer\n    index_to_sentiment = {v: k for k, v in sentiment_mapping.items()}\n    predicted_label = index_to_sentiment.get(predicted_index, \"unknown\")\n    \n    #keyakinan hasil prediksi\n    confidence = probabilities[0][predicted_index]\n\n    print(f\"Teks: {text}\")\n    print(f\"Prediksi label: {predicted_label} (Confidence: {confidence:.2f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:57:43.938705Z","iopub.execute_input":"2025-01-25T14:57:43.939000Z","iopub.status.idle":"2025-01-25T14:57:43.944500Z","shell.execute_reply.started":"2025-01-25T14:57:43.938977Z","shell.execute_reply":"2025-01-25T14:57:43.943636Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"text = \"aku sedang jalan-jalan di yogyakarta\"","metadata":{"id":"w1xKMaEzAnNO","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:04:36.388804Z","iopub.execute_input":"2025-01-25T15:04:36.389165Z","iopub.status.idle":"2025-01-25T15:04:36.393367Z","shell.execute_reply.started":"2025-01-25T15:04:36.389137Z","shell.execute_reply":"2025-01-25T15:04:36.392344Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"predict(text)","metadata":{"id":"xdbOMA-9rU5C","outputId":"f4991ad1-df66-4f1a-a03c-4b19e974c963","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:04:37.189759Z","iopub.execute_input":"2025-01-25T15:04:37.190057Z","iopub.status.idle":"2025-01-25T15:04:37.380131Z","shell.execute_reply.started":"2025-01-25T15:04:37.190034Z","shell.execute_reply":"2025-01-25T15:04:37.379431Z"}},"outputs":[{"name":"stdout","text":"Teks: aku sedang jalan-jalan di yogyakarta\nPrediksi label: neutral (Confidence: 1.00)\n","output_type":"stream"}],"execution_count":71},{"cell_type":"markdown","source":"## Save model\n","metadata":{"id":"XCkTkOUAvEJ0"}},{"cell_type":"code","source":"save_path = \"finetuned-model\"","metadata":{"id":"7k5ExWlP4oY6","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:43:36.528851Z","iopub.execute_input":"2025-01-25T14:43:36.529190Z","iopub.status.idle":"2025-01-25T14:43:36.532876Z","shell.execute_reply.started":"2025-01-25T14:43:36.529162Z","shell.execute_reply":"2025-01-25T14:43:36.532027Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"os.mkdir(save_path)","metadata":{"id":"e-Resnbo4lNE","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:43:37.026763Z","iopub.execute_input":"2025-01-25T14:43:37.027048Z","iopub.status.idle":"2025-01-25T14:43:37.030968Z","shell.execute_reply.started":"2025-01-25T14:43:37.027026Z","shell.execute_reply":"2025-01-25T14:43:37.030049Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"model.save_pretrained(save_path)","metadata":{"id":"ErK0cR0RAnNa","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:43:37.588791Z","iopub.execute_input":"2025-01-25T14:43:37.589112Z","iopub.status.idle":"2025-01-25T14:43:39.012821Z","shell.execute_reply.started":"2025-01-25T14:43:37.589087Z","shell.execute_reply":"2025-01-25T14:43:39.012112Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"save_directory = \"./tokenizer_directory\"  # Specify the directory to save the tokenizer\ntokenizer.save_pretrained(save_directory)","metadata":{"id":"es65fRS1vHzB","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T15:36:53.176798Z","iopub.execute_input":"2025-01-25T15:36:53.177120Z","iopub.status.idle":"2025-01-25T15:36:53.199219Z","shell.execute_reply.started":"2025-01-25T15:36:53.177097Z","shell.execute_reply":"2025-01-25T15:36:53.198592Z"}},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"('./tokenizer_directory/tokenizer_config.json',\n './tokenizer_directory/special_tokens_map.json',\n './tokenizer_directory/vocab.txt',\n './tokenizer_directory/added_tokens.json',\n './tokenizer_directory/tokenizer.json')"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"","metadata":{"id":"UN6B5YcEAnNd","trusted":true},"outputs":[],"execution_count":null}]}